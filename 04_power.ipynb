{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd  # for data storage and manipulation\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import seaborn as sns  # for plotting\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# common.py is a local file with shared constants\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 5,220 records from data.tsv\n",
      "read 145 records from meta.tsv\n"
     ]
    }
   ],
   "source": [
    "comments = {}  # Log any comments through processing and report them all at the end.\n",
    "\n",
    "def safe_load(f):\n",
    "    if os.path.isfile(f):\n",
    "        df = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "        print(\"read {:,} records from {}\".format(len(df.index), f))\n",
    "        return df\n",
    "    else:\n",
    "        print(\"01_collect_data.ipynb needs to be run before any analyses.\")\n",
    "        return None\n",
    "\n",
    "data = safe_load(common.data_file)\n",
    "meta = safe_load(common.meta_file)\n",
    "\n",
    "# Add a field (won't be saved to disk) to make hit rate statistics easier.\n",
    "data['is_hit'] = (data['Hit_Miss_raw'] == \"'Hit'\")\n",
    "# Scale percentages to align with anxiety scores in shared y-axes\n",
    "meta['hit_rate'] = meta['py_hit_rate'] * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Power analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of power analysis are appropriate. First, the necessary sample size should have been calculated prior to carrying it out this experiment. It was already performed and reported in the paper. Second, after calculating our results, it's interesting to see how many participants would we have needed for our small difference to have been significant? Or, in other words, how many additional people would we have to recruit (assuming the same distribution we have so far) to p-hack our way to p<0.05? The equation for a one-sample t-test follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t = \\frac{ \\bar{x} - \\mu }{ \\frac{s}{\\sqrt{n}} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n = \\frac{ts}{\\bar{x} - \\mu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We would need 10,115 participants for 49.85% to be a significant result.\n"
     ]
    }
   ],
   "source": [
    "actual_mean = np.mean(data['is_hit'])\n",
    "actual_sd = np.std(meta['hit_rate'])\n",
    "expected_mean = 0.500\n",
    "required_t = 1.96\n",
    "required_n = (required_t * actual_sd) / abs(actual_mean - expected_mean)\n",
    "\n",
    "print(\"We would need {:,} participants for {:0.2%} to be a significant result.\".format(\n",
    "    int(required_n), actual_mean\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
